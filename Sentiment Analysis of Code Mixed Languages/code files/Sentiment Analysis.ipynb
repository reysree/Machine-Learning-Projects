{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.11:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [02/Apr/2020 14:34:40] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [02/Apr/2020 14:34:40] \"GET /sentimentanalysis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2020 14:35:05] \"POST /sentimentanalysis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2020 14:35:53] \"GET /sentimentanalysis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2020 14:35:53] \"GET / HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template,jsonify\n",
    "import urllib3, requests, json, os\n",
    "import re\n",
    "from PyDictionary import PyDictionary\n",
    "from googletrans import Translator\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "l=[]\n",
    "temp=[]\n",
    "stop_words=[]\n",
    "translator = Translator()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/sentimentanalysis', methods=['POST'])\n",
    "def hello_world():\n",
    "    name = request.form.get('name')    \n",
    "    l=process(name)\n",
    "    l=convert(l)\n",
    "    manual_check(l)\n",
    "    l=pre_process(l)\n",
    "    l=final_filter(temp,l)\n",
    "    result = sentiment_analysis(l)\n",
    "    return render_template(\"result.html\",result = result)\n",
    "\n",
    "def process(text):\n",
    "    regex = r'\\b\\w+\\b'\n",
    "    l=re.findall(regex,text)\n",
    "    return l\n",
    "\n",
    "def translate(i,n,line):\n",
    "    translations = translator.translate([i], dest='en')\n",
    "    for translation in translations:\n",
    "        d=translation.text\n",
    "        line[n]=d\n",
    "           \n",
    "def convert(line):\n",
    "    for n,i in  enumerate(line):\n",
    "        if not wordnet.synsets(i):\n",
    "            translate(i,n,line)\n",
    "        else:\n",
    "            continue;\n",
    "    return line\n",
    "\n",
    "def manual_check(l):\n",
    "    stop_words=['a','an','and','are','at','away','be','but','by','can','could','did','do','done','does','every','everybody','ever',\n",
    "            'for','get','give','go','going','goods','got','he','had','have','has','having','his','himself','him','how'\n",
    "           ,'i','I','if','in','it','itself','is','know','knew','knows','knowing','large','late','lately','later','man','me'\n",
    "           ,'my','mom','men','might','may','member','myself','mr','ms','mrs','need','new','newer','newest','now','number','nothing'\n",
    "           ,'of','on','old','once','other','others','own','part','parting','parts','per','present','presenting','presented','presents'\n",
    "           ,'put','puts','quite','said','say','saw','same','second','seconds','seem','says','she','so','some','someone','somebody'\n",
    "           ,'side','sides','something','somewhere','states','state','such','the','that','them','this','those','them','therefore'\n",
    "           ,'think','thinks','thing','things','three','through','thus','today','together','tomorrow','to','u','under','until'\n",
    "           ,'up','us','use','used','uses','we','was','want','wanted','which','where','what','when','while','who','with','within'\n",
    "           ,'work','working','worked','would','works','you','yet','your','young','yours']\n",
    "    for i in l:\n",
    "        if i not in stop_words:\n",
    "            temp.append(i)\n",
    "\n",
    "def pre_process(l):\n",
    "    process=\"\"\n",
    "    for i in l:\n",
    "        process=process+i+\" \"\n",
    "    process=process.strip()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = word_tokenize(process)\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "    filtered_sentence = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def final_filter(temp,l):\n",
    "    res_list=[]\n",
    "    flag=0;\n",
    "    for i in temp:\n",
    "        if((i not in l) and (i in stop_words)):\n",
    "            res_list=temp.copy()\n",
    "            flag=1\n",
    "            break;\n",
    "    if(flag==0):\n",
    "           res_list=l.copy()\n",
    "    return res_list\n",
    "\n",
    "def sentiment_analysis(l):\n",
    "    final_text=\"\"\n",
    "    with open('sentiment.txt', 'w') as filehandle:\n",
    "        for listitem in l:\n",
    "            filehandle.write('%s ' % listitem)\n",
    "    lineList = [line.rstrip('\\n') for line in open('sentiment.txt')]\n",
    "    s=\"\"\n",
    "    for i in lineList:\n",
    "        s=s+i;\n",
    "    obj=TextBlob(s)\n",
    "    sentiment=obj.sentiment.polarity\n",
    "    return round(sentiment,2)*100\n",
    "\n",
    "@app.route('/sentimentanalysis', methods = ['GET'])\n",
    "def render_html():\n",
    "    return render_template('home.html')\n",
    "port = os.getenv('PORT', '5000')\n",
    "if __name__ == \"__main__\":\n",
    "    app.debug = False\n",
    "    app.run(host='127.0.0.11', port=int(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
