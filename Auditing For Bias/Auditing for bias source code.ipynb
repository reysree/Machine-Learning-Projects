{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "623871f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from fairlearn.reductions import EqualizedOdds\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from fairlearn.metrics import equalized_odds_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55563db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataset are :  53\n",
      "(7214, 53)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"recid.csv\")\n",
    "num_cols = train.shape[1]\n",
    "print(\"Number of columns in the dataset are : \",num_cols)\n",
    "train.head(5)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ef040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age,\n",
    "# c_charge_degree,\n",
    "# race,\n",
    "# age_cat,\n",
    "# score_text,\n",
    "# sex,\n",
    "# priors_count,\n",
    "# days_b_screening_arrest,\n",
    "# decile_score,\n",
    "# is_recid,\n",
    "# two_year_recid,\n",
    "# c_jail_in,\n",
    "# c_jail_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f60fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013 6:03</td>\n",
       "      <td>8/14/2013 5:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/26/2013 3:45</td>\n",
       "      <td>2/5/2013 5:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4/13/2013 4:58</td>\n",
       "      <td>4/14/2013 7:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>High</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age c_charge_degree              race          age_cat score_text   sex  \\\n",
       "0   69               F             Other  Greater than 45        Low  Male   \n",
       "1   34               F  African-American          25 - 45        Low  Male   \n",
       "2   24               F  African-American     Less than 25        Low  Male   \n",
       "3   23               F  African-American     Less than 25       High  Male   \n",
       "4   43               F             Other          25 - 45        Low  Male   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0             0                     -1.0             1         0   \n",
       "1             0                     -1.0             3         1   \n",
       "2             4                     -1.0             4         1   \n",
       "3             1                      NaN             8         0   \n",
       "4             2                      NaN             1         0   \n",
       "\n",
       "   two_year_recid       c_jail_in      c_jail_out  \n",
       "0               0  8/13/2013 6:03  8/14/2013 5:41  \n",
       "1               1  1/26/2013 3:45   2/5/2013 5:36  \n",
       "2               1  4/13/2013 4:58  4/14/2013 7:02  \n",
       "3               0             NaN             NaN  \n",
       "4               0             NaN             NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train[['age', 'c_charge_degree','race','age_cat', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest'\n",
    "                              ,'decile_score', 'is_recid','two_year_recid','c_jail_in','c_jail_out']]\n",
    "print(train_new.shape)\n",
    "train_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "230b14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6907, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013 6:03</td>\n",
       "      <td>8/14/2013 5:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/26/2013 3:45</td>\n",
       "      <td>2/5/2013 5:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4/13/2013 4:58</td>\n",
       "      <td>4/14/2013 7:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2013 4:50</td>\n",
       "      <td>12/1/2013 12:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2/18/2014 5:08</td>\n",
       "      <td>2/24/2014 12:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age c_charge_degree              race          age_cat score_text   sex  \\\n",
       "0   69               F             Other  Greater than 45        Low  Male   \n",
       "1   34               F  African-American          25 - 45        Low  Male   \n",
       "2   24               F  African-American     Less than 25        Low  Male   \n",
       "5   44               M             Other          25 - 45        Low  Male   \n",
       "6   41               F         Caucasian          25 - 45     Medium  Male   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0             0                     -1.0             1         0   \n",
       "1             0                     -1.0             3         1   \n",
       "2             4                     -1.0             4         1   \n",
       "5             0                      0.0             1         0   \n",
       "6            14                     -1.0             6         1   \n",
       "\n",
       "   two_year_recid        c_jail_in       c_jail_out  \n",
       "0               0   8/13/2013 6:03   8/14/2013 5:41  \n",
       "1               1   1/26/2013 3:45    2/5/2013 5:36  \n",
       "2               1   4/13/2013 4:58   4/14/2013 7:02  \n",
       "5               0  11/30/2013 4:50  12/1/2013 12:28  \n",
       "6               1   2/18/2014 5:08  2/24/2014 12:18  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train_new.dropna()\n",
    "\n",
    "print(train_new.shape)\n",
    "train_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9163d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6172, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013 6:03</td>\n",
       "      <td>8/14/2013 5:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/26/2013 3:45</td>\n",
       "      <td>2/5/2013 5:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4/13/2013 4:58</td>\n",
       "      <td>4/14/2013 7:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2013 4:50</td>\n",
       "      <td>12/1/2013 12:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2/18/2014 5:08</td>\n",
       "      <td>2/24/2014 12:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age c_charge_degree              race          age_cat score_text   sex  \\\n",
       "0   69               F             Other  Greater than 45        Low  Male   \n",
       "1   34               F  African-American          25 - 45        Low  Male   \n",
       "2   24               F  African-American     Less than 25        Low  Male   \n",
       "5   44               M             Other          25 - 45        Low  Male   \n",
       "6   41               F         Caucasian          25 - 45     Medium  Male   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0             0                     -1.0             1         0   \n",
       "1             0                     -1.0             3         1   \n",
       "2             4                     -1.0             4         1   \n",
       "5             0                      0.0             1         0   \n",
       "6            14                     -1.0             6         1   \n",
       "\n",
       "   two_year_recid        c_jail_in       c_jail_out  \n",
       "0               0   8/13/2013 6:03   8/14/2013 5:41  \n",
       "1               1   1/26/2013 3:45    2/5/2013 5:36  \n",
       "2               1   4/13/2013 4:58   4/14/2013 7:02  \n",
       "5               0  11/30/2013 4:50  12/1/2013 12:28  \n",
       "6               1   2/18/2014 5:08  2/24/2014 12:18  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train_new[train_new['is_recid'] != -1]\n",
    "train_new = train_new[train_new['c_charge_degree'] != \"O\"]\n",
    "train_new = train_new[train_new['score_text'] != 'N/A']\n",
    "train_new = train_new[train_new['days_b_screening_arrest'] <= 30]\n",
    "train_new = train_new[train_new['days_b_screening_arrest'] >= -30]\n",
    "\n",
    "\n",
    "print(train_new.shape)\n",
    "train_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e6b69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6172, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age c_charge_degree              race          age_cat score_text   sex  \\\n",
       "0   69               F             Other  Greater than 45        Low  Male   \n",
       "1   34               F  African-American          25 - 45        Low  Male   \n",
       "2   24               F  African-American     Less than 25        Low  Male   \n",
       "5   44               M             Other          25 - 45        Low  Male   \n",
       "6   41               F         Caucasian          25 - 45     Medium  Male   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  decile_score  two_year_recid  \n",
       "0             0                     -1.0             1               0  \n",
       "1             0                     -1.0             3               1  \n",
       "2             4                     -1.0             4               1  \n",
       "5             0                      0.0             1               0  \n",
       "6            14                     -1.0             6               1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train_new.drop(['c_jail_in','c_jail_out','is_recid'],axis=1)\n",
    "print(train_new.shape)\n",
    "train_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f874b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_new['crime_factor'] = pd.Categorical(train_new['c_charge_degree'])\n",
    "# train_new['age_factor'] = pd.Categorical(train_new['age_cat'])\n",
    "# # train_new['age_factor'] = train_new['age_factor'].cat.reorder_categories(\n",
    "# #     [train_new['age_factor'].cat.categories[0]] + list(train_new['age_factor'].cat.categories[1:]))\n",
    "# train_new['race_factor '] = pd.Categorical(train_new['race'])\n",
    "# # train_new['race_factor'] = train_new['race_factor'].cat.reorder_categories(\n",
    "# #     list(train_new['race_factor'].cat.categories[:2]) + [train_new['race_factor'].cat.categories[2]]\n",
    "# #     + list(train_new['race_factor'].cat.categories[3:]))\n",
    "# train_new['gender_factor'] = pd.Categorical(train_new['sex'], categories=['Female', 'Male'], ordered=False)\n",
    "# # train_new['gender_factor'] = train_new['gender_factor'].cat.reorder_categories(\n",
    "# #     list(train_new['gender_factor'].cat.categories[1:]) + [train_new['gender_factor'].cat.categories[0]])\n",
    "# train_new['score_factor'] = pd.Categorical(train_new['score_text'] != 'Low',\n",
    "#                      categories=[False, True], ordered=False).rename_categories(['LowScore', 'HighScore'])\n",
    "\n",
    "# print(train_new.shape)\n",
    "# train_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7be02be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'priors_count', 'days_b_screening_arrest', 'decile_score',\n",
       "       'two_year_recid', 'c_charge_degree_F', 'c_charge_degree_M',\n",
       "       'race_African-American', 'race_Asian', 'race_Caucasian',\n",
       "       'race_Hispanic', 'race_Native American', 'race_Other',\n",
       "       'age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25',\n",
       "       'score_text_High', 'score_text_Low', 'score_text_Medium', 'sex_Female',\n",
       "       'sex_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final = pd.get_dummies(train_new)\n",
    "train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516e47e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4135, 20)\n",
      "Shape of X_test: (2037, 20)\n",
      "Shape of y_train: (4135,)\n",
      "Shape of y_test: (2037,)\n"
     ]
    }
   ],
   "source": [
    "train_final = train_final.drop('two_year_recid',axis=1)\n",
    "X = train_final\n",
    "Y = train_new['two_year_recid']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=18)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb60624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6774668630338734\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        598                        351\n",
      "is_not_recividated                    306                        782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      1088\n",
      "           1       0.66      0.63      0.65       949\n",
      "\n",
      "    accuracy                           0.68      2037\n",
      "   macro avg       0.68      0.67      0.67      2037\n",
      "weighted avg       0.68      0.68      0.68      2037\n",
      "\n",
      "True Negatives       :  782\n",
      "False Positives      :  306\n",
      "False Negatives      :  351\n",
      "True Positives       :  598\n",
      "False positive predictions by the model\n",
      "African-American:  201\n",
      "Caucasian:  72\n",
      "Total False Positives:  306\n",
      "% of False positives\n",
      "African-American: 0.66\n",
      "Caucasian: 0.24\n",
      "True positive predictions by the model\n",
      "African-American:  403\n",
      "Caucasian:  146\n",
      "Total True Positives:  598\n",
      "% of True positives\n",
      "African-American: 0.67\n",
      "Caucasian: 0.24\n",
      "False negative predictions by the model\n",
      "African-American:  151\n",
      "Caucasian:  143\n",
      "Total False Negatives:  351\n",
      "% of False negatives\n",
      "African-American: 0.27\n",
      "Caucasian: 0.49\n",
      "True negative predictions by the model\n",
      "African-American:  300\n",
      "Caucasian:  335\n",
      "Total True Negatives:  782\n",
      "% of True negatives\n",
      "African-American: 0.38\n",
      "Caucasian: 0.43\n"
     ]
    }
   ],
   "source": [
    "# create a logistic regression object with iterations parameter and gini index parameter\n",
    "logreg = LogisticRegression(max_iter=1000, solver='lbfgs', penalty='l2', random_state=18, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "np.mean(scores)\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as African American by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_African-American'].value_counts()[1]\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as Caucasian by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_Caucasian'].value_counts()[1]\n",
    "\n",
    "[[tn , fp],[fn , tp]] = confusion_matrix(y_test,y_pred)\n",
    "print(\"True Negatives       : \", tn)\n",
    "print(\"False Positives      : \", fp)\n",
    "print(\"False Negatives      : \", fn)\n",
    "print(\"True Positives       : \", tp)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of false positive predictions\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "\n",
    "# filter test set to get only false positive predictions\n",
    "fp_data = X_test.iloc[fp_indices]\n",
    "\n",
    "# count number of false positives for African-American and Caucasian races\n",
    "fp_African = fp_data['race_African-American'].sum()\n",
    "fp_Caucasian = fp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of false positives\n",
    "fp_total = len(fp_data)\n",
    "\n",
    "# print results\n",
    "print(\"False positive predictions by the model\")\n",
    "print(\"African-American: \", fp_African)\n",
    "print(\"Caucasian: \", fp_Caucasian)\n",
    "print(\"Total False Positives: \", fp_total)\n",
    "\n",
    "print(\"% of False positives\")\n",
    "print(\"African-American: %.2f\" % (fp_African / fp_total))\n",
    "print(\"Caucasian: %.2f\" % (fp_Caucasian / fp_total))\n",
    "\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of true positive predictions\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "\n",
    "# filter test set to get only true positive predictions\n",
    "tp_data = X_test.iloc[tp_indices]\n",
    "\n",
    "# count number of true positives for African-American and Caucasian races\n",
    "tp_African = tp_data['race_African-American'].sum()\n",
    "tp_Caucasian = tp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of true positives\n",
    "tp_total = len(tp_data)\n",
    "\n",
    "# print results\n",
    "print(\"True positive predictions by the model\")\n",
    "print(\"African-American: \", tp_African)\n",
    "print(\"Caucasian: \", tp_Caucasian)\n",
    "print(\"Total True Positives: \", tp_total)\n",
    "\n",
    "print(\"% of True positives\")\n",
    "print(\"African-American: %.2f\" % (tp_African / tp_total))\n",
    "print(\"Caucasian: %.2f\" % (tp_Caucasian / tp_total))\n",
    "\n",
    "# get indices of false negative predictions\n",
    "fn_indices = np.where((y_pred == 0) & (y_test == 1))[0]\n",
    "\n",
    "# filter test set to get only false negative predictions\n",
    "fn_data = X_test.iloc[fn_indices]\n",
    "\n",
    "# count number of false negatives for African-American and Caucasian races\n",
    "fn_African = fn_data['race_African-American'].sum()\n",
    "fn_Caucasian = fn_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of false negatives\n",
    "fn_total = len(fn_data)\n",
    "\n",
    "# print results\n",
    "print(\"False negative predictions by the model\")\n",
    "print(\"African-American: \", fn_African)\n",
    "print(\"Caucasian: \", fn_Caucasian)\n",
    "print(\"Total False Negatives: \", fn_total)\n",
    "\n",
    "print(\"% of False negatives\")\n",
    "print(\"African-American: %.2f\" % (fn_African / (fn_African + tp_African)))\n",
    "print(\"Caucasian: %.2f\" % (fn_Caucasian / (fn_Caucasian + tp_Caucasian)))\n",
    "\n",
    "\n",
    "# get indices of true negative predictions\n",
    "tn_indices = np.where((y_pred == 0) & (y_test == 0))[0]\n",
    "\n",
    "# filter test set to get only true negative predictions\n",
    "tn_data = X_test.iloc[tn_indices]\n",
    "\n",
    "# count number of true negatives for African-American and Caucasian races\n",
    "tn_African = tn_data['race_African-American'].sum()\n",
    "tn_Caucasian = tn_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of true negatives\n",
    "tn_total = len(tn_data)\n",
    "\n",
    "# print results\n",
    "print(\"True negative predictions by the model\")\n",
    "print(\"African-American: \", tn_African)\n",
    "print(\"Caucasian: \", tn_Caucasian)\n",
    "print(\"Total True Negatives: \", tn_total)\n",
    "\n",
    "print(\"% of True negatives\")\n",
    "print(\"African-American: %.2f\" % (tn_African / tn_total))\n",
    "print(\"Caucasian: %.2f\" % (tn_Caucasian / tn_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ac309bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.648993618065783\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        600                        349\n",
      "is_not_recividated                    366                        722\n",
      "Demographic parity difference:  0.03174402135425175\n",
      "Equalized odds difference:  0.04706763844424766\n",
      "False positives for the Caucasian group:  133\n",
      "False positives for the African-American group:  169\n"
     ]
    }
   ],
   "source": [
    "# Define the sensitive features\n",
    "sensitive_features = np.array([X_train['race_Caucasian'], X_train['race_African-American']]).T\n",
    "sensitive_features_test = np.array([X_test['race_Caucasian'], X_test['race_African-American']]).T\n",
    "\n",
    "# Define the fairness constraint\n",
    "constraint = EqualizedOdds()\n",
    "\n",
    "# Define the model and the optimizer\n",
    "logreg = LogisticRegression(max_iter=1000, solver='lbfgs', penalty='l2', random_state=18, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "#ForestClassifier(n_estimators=100)\n",
    "optimizer = ExponentiatedGradient(logreg, constraints=constraint)\n",
    "\n",
    "# Fit the optimizer to the training data\n",
    "optimizer.fit(X_train, y_train, sensitive_features=sensitive_features)\n",
    "\n",
    "# Evaluate the fairness of the model on the test data\n",
    "y_pred = optimizer.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "dp_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sensitive_features_test)\n",
    "eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=sensitive_features_test)\n",
    "print(\"Demographic parity difference: \", dp_diff)\n",
    "print(\"Equalized odds difference: \", eo_diff)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cceaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives for the Caucasian group:  133\n",
      "False positives for the African-American group:  169\n",
      "False positives for both groups:  966\n",
      "False positive rate for the Caucasian group:  0.13768115942028986\n",
      "False positive rate for the African-American group:  0.17494824016563146\n",
      "False positive rate for both groups:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for both groups\n",
    "cm_both = confusion_matrix(y_test, y_pred)\n",
    "false_positives_both = cm_both[0, 1] + cm_both[1, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)\n",
    "print(\"False positives for both groups: \", false_positives_both)\n",
    "\n",
    "# Compute the false positive rate for both groups\n",
    "total_negatives = cm_both[0, 1] + cm_both[1, 1]\n",
    "fpr_caucasian = false_positives_caucasian / total_negatives\n",
    "fpr_african_american = false_positives_african_american / total_negatives\n",
    "fpr_both = false_positives_both / total_negatives\n",
    "\n",
    "print(\"False positive rate for the Caucasian group: \", fpr_caucasian)\n",
    "print(\"False positive rate for the African-American group: \", fpr_african_american)\n",
    "print(\"False positive rate for both groups: \", fpr_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95da7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6475208640157094\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        465                        484\n",
      "is_not_recividated                    234                        854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70      1088\n",
      "           1       0.67      0.49      0.56       949\n",
      "\n",
      "    accuracy                           0.65      2037\n",
      "   macro avg       0.65      0.64      0.63      2037\n",
      "weighted avg       0.65      0.65      0.64      2037\n",
      "\n",
      "True Negatives       :  854\n",
      "False Positives      :  234\n",
      "False Negatives      :  484\n",
      "True Positives       :  465\n",
      "False positive predictions by the model\n",
      "African-American:  156\n",
      "Caucasian:  55\n",
      "Total False Positives:  234\n",
      "% of False positives\n",
      "African-American: 0.67\n",
      "Caucasian: 0.24\n",
      "True positive predictions by the model\n",
      "African-American:  327\n",
      "Caucasian:  107\n",
      "Total True Positives:  465\n",
      "% of True positives\n",
      "African-American: 0.70\n",
      "Caucasian: 0.23\n"
     ]
    }
   ],
   "source": [
    "# create a logistic regression object with iterations parameter and gini index parameter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create a DecisionTreeClassifier object with Gini index as the splitting criterion\n",
    "dt = DecisionTreeClassifier(max_depth=1, criterion='gini')\n",
    "\n",
    "# fit the model to the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "np.mean(scores)\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as African American by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_African-American'].value_counts()[1]\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as Caucasian by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_Caucasian'].value_counts()[1]\n",
    "\n",
    "[[tn , fp],[fn , tp]] = confusion_matrix(y_test,y_pred)\n",
    "print(\"True Negatives       : \", tn)\n",
    "print(\"False Positives      : \", fp)\n",
    "print(\"False Negatives      : \", fn)\n",
    "print(\"True Positives       : \", tp)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of false positive predictions\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "\n",
    "# filter test set to get only false positive predictions\n",
    "fp_data = X_test.iloc[fp_indices]\n",
    "\n",
    "# count number of false positives for African-American and Caucasian races\n",
    "fp_African = fp_data['race_African-American'].sum()\n",
    "fp_Caucasian = fp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of false positives\n",
    "fp_total = len(fp_data)\n",
    "\n",
    "# print results\n",
    "print(\"False positive predictions by the model\")\n",
    "print(\"African-American: \", fp_African)\n",
    "print(\"Caucasian: \", fp_Caucasian)\n",
    "print(\"Total False Positives: \", fp_total)\n",
    "\n",
    "print(\"% of False positives\")\n",
    "print(\"African-American: %.2f\" % (fp_African / fp_total))\n",
    "print(\"Caucasian: %.2f\" % (fp_Caucasian / fp_total))\n",
    "\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of true positive predictions\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "\n",
    "# filter test set to get only true positive predictions\n",
    "tp_data = X_test.iloc[tp_indices]\n",
    "\n",
    "# count number of true positives for African-American and Caucasian races\n",
    "tp_African = tp_data['race_African-American'].sum()\n",
    "tp_Caucasian = tp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of true positives\n",
    "tp_total = len(tp_data)\n",
    "\n",
    "# print results\n",
    "print(\"True positive predictions by the model\")\n",
    "print(\"African-American: \", tp_African)\n",
    "print(\"Caucasian: \", tp_Caucasian)\n",
    "print(\"Total True Positives: \", tp_total)\n",
    "\n",
    "print(\"% of True positives\")\n",
    "print(\"African-American: %.2f\" % (tp_African / tp_total))\n",
    "print(\"Caucasian: %.2f\" % (tp_Caucasian / tp_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c851718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6514482081492391\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        545                        404\n",
      "is_not_recividated                    306                        782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69      1088\n",
      "           1       0.64      0.57      0.61       949\n",
      "\n",
      "    accuracy                           0.65      2037\n",
      "   macro avg       0.65      0.65      0.65      2037\n",
      "weighted avg       0.65      0.65      0.65      2037\n",
      "\n",
      "True Negatives       :  782\n",
      "False Positives      :  306\n",
      "False Negatives      :  404\n",
      "True Positives       :  545\n",
      "False positive predictions by the model\n",
      "African-American:  174\n",
      "Caucasian:  87\n",
      "Total False Positives:  306\n",
      "% of False positives\n",
      "African-American: 0.57\n",
      "Caucasian: 0.28\n",
      "True positive predictions by the model\n",
      "African-American:  360\n",
      "Caucasian:  133\n",
      "Total True Positives:  545\n",
      "% of True positives\n",
      "African-American: 0.66\n",
      "Caucasian: 0.24\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "np.mean(scores)\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as African American by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_African-American'].value_counts()[1]\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as Caucasian by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_Caucasian'].value_counts()[1]\n",
    "\n",
    "[[tn , fp],[fn , tp]] = confusion_matrix(y_test,y_pred)\n",
    "print(\"True Negatives       : \", tn)\n",
    "print(\"False Positives      : \", fp)\n",
    "print(\"False Negatives      : \", fn)\n",
    "print(\"True Positives       : \", tp)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of false positive predictions\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "\n",
    "# filter test set to get only false positive predictions\n",
    "fp_data = X_test.iloc[fp_indices]\n",
    "\n",
    "# count number of false positives for African-American and Caucasian races\n",
    "fp_African = fp_data['race_African-American'].sum()\n",
    "fp_Caucasian = fp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of false positives\n",
    "fp_total = len(fp_data)\n",
    "\n",
    "# print results\n",
    "print(\"False positive predictions by the model\")\n",
    "print(\"African-American: \", fp_African)\n",
    "print(\"Caucasian: \", fp_Caucasian)\n",
    "print(\"Total False Positives: \", fp_total)\n",
    "\n",
    "print(\"% of False positives\")\n",
    "print(\"African-American: %.2f\" % (fp_African / fp_total))\n",
    "print(\"Caucasian: %.2f\" % (fp_Caucasian / fp_total))\n",
    "\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of true positive predictions\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "\n",
    "# filter test set to get only true positive predictions\n",
    "tp_data = X_test.iloc[tp_indices]\n",
    "\n",
    "# count number of true positives for African-American and Caucasian races\n",
    "tp_African = tp_data['race_African-American'].sum()\n",
    "tp_Caucasian = tp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of true positives\n",
    "tp_total = len(tp_data)\n",
    "\n",
    "# print results\n",
    "print(\"True positive predictions by the model\")\n",
    "print(\"African-American: \", tp_African)\n",
    "print(\"Caucasian: \", tp_Caucasian)\n",
    "print(\"Total True Positives: \", tp_total)\n",
    "\n",
    "print(\"% of True positives\")\n",
    "print(\"African-American: %.2f\" % (tp_African / tp_total))\n",
    "print(\"Caucasian: %.2f\" % (tp_Caucasian / tp_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a84f0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6190476190476191\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        546                        403\n",
      "is_not_recividated                    373                        715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1088\n",
      "           1       0.59      0.58      0.58       949\n",
      "\n",
      "    accuracy                           0.62      2037\n",
      "   macro avg       0.62      0.62      0.62      2037\n",
      "weighted avg       0.62      0.62      0.62      2037\n",
      "\n",
      "True Negatives       :  715\n",
      "False Positives      :  373\n",
      "False Negatives      :  403\n",
      "True Positives       :  546\n",
      "False positive predictions by the model\n",
      "African-American:  201\n",
      "Caucasian:  114\n",
      "Total False Positives:  373\n",
      "% of False positives\n",
      "African-American: 0.54\n",
      "Caucasian: 0.31\n",
      "True positive predictions by the model\n",
      "African-American:  342\n",
      "Caucasian:  142\n",
      "Total True Positives:  546\n",
      "% of True positives\n",
      "African-American: 0.63\n",
      "Caucasian: 0.26\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(criterion='gini')\n",
    "adaboost = AdaBoostClassifier(estimator=base_estimator, n_estimators=20)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = adaboost.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "np.mean(scores)\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as African American by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_African-American'].value_counts()[1]\n",
    "\n",
    "\"\"\" Predicted +ve and are categorized as Caucasian by the race variable\"\"\"\n",
    "X_test[y_pred == 1]['race_Caucasian'].value_counts()[1]\n",
    "\n",
    "[[tn , fp],[fn , tp]] = confusion_matrix(y_test,y_pred)\n",
    "print(\"True Negatives       : \", tn)\n",
    "print(\"False Positives      : \", fp)\n",
    "print(\"False Negatives      : \", fn)\n",
    "print(\"True Positives       : \", tp)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of false positive predictions\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "\n",
    "# filter test set to get only false positive predictions\n",
    "fp_data = X_test.iloc[fp_indices]\n",
    "\n",
    "# count number of false positives for African-American and Caucasian races\n",
    "fp_African = fp_data['race_African-American'].sum()\n",
    "fp_Caucasian = fp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of false positives\n",
    "fp_total = len(fp_data)\n",
    "\n",
    "# print results\n",
    "print(\"False positive predictions by the model\")\n",
    "print(\"African-American: \", fp_African)\n",
    "print(\"Caucasian: \", fp_Caucasian)\n",
    "print(\"Total False Positives: \", fp_total)\n",
    "\n",
    "print(\"% of False positives\")\n",
    "print(\"African-American: %.2f\" % (fp_African / fp_total))\n",
    "print(\"Caucasian: %.2f\" % (fp_Caucasian / fp_total))\n",
    "\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get indices of true positive predictions\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "\n",
    "# filter test set to get only true positive predictions\n",
    "tp_data = X_test.iloc[tp_indices]\n",
    "\n",
    "# count number of true positives for African-American and Caucasian races\n",
    "tp_African = tp_data['race_African-American'].sum()\n",
    "tp_Caucasian = tp_data['race_Caucasian'].sum()\n",
    "\n",
    "# calculate total number of true positives\n",
    "tp_total = len(tp_data)\n",
    "\n",
    "# print results\n",
    "print(\"True positive predictions by the model\")\n",
    "print(\"African-American: \", tp_African)\n",
    "print(\"Caucasian: \", tp_Caucasian)\n",
    "print(\"Total True Positives: \", tp_total)\n",
    "\n",
    "print(\"% of True positives\")\n",
    "print(\"African-American: %.2f\" % (tp_African / tp_total))\n",
    "print(\"Caucasian: %.2f\" % (tp_Caucasian / tp_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfdc59ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n",
      "Accuracy: 0.6612665684830633\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        552                        397\n",
      "is_not_recividated                    293                        795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      1088\n",
      "           1       0.65      0.58      0.62       949\n",
      "\n",
      "    accuracy                           0.66      2037\n",
      "   macro avg       0.66      0.66      0.66      2037\n",
      "weighted avg       0.66      0.66      0.66      2037\n",
      "\n",
      "[20:38:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n",
      "[20:38:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n",
      "[20:38:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n",
      "[20:38:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n",
      "[20:38:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"base_estimator\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6532043530834342"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# define the base estimator\n",
    "base_estimator = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# define the xgboost model\n",
    "xgb_model = xgb.XGBClassifier(base_estimator=base_estimator, n_estimators=200)\n",
    "\n",
    "# train the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "cm = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(cm, index=['is_recividated', 'is_not_recividated'], columns=['predicted_recividated', 'predicted_not_recividated'])\n",
    "print(confusion)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# calculate the cross validation score\n",
    "scores = cross_val_score(xgb_model, X_train, y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdb929fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4135, 2)\n",
      "2037\n",
      "(2037,)\n",
      "Demographic parity difference:  0.015649343574658192\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.reductions import EqualizedOdds\n",
    "\n",
    "# Define the sensitive features\n",
    "sensitive_features = np.array([X_train['race_Caucasian'], X_train['race_African-American']]).T\n",
    "sensitive_features_test = np.array([X_test['race_Caucasian'], X_test['race_African-American']]).T\n",
    "print(sensitive_features.shape)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "# Define the fairness constraint\n",
    "constraint = DemographicParity()\n",
    "\n",
    "# Define the model and the optimizer\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs', penalty='l2', random_state=18, n_jobs=-1, class_weight='balanced')\n",
    "optimizer = ExponentiatedGradient(model, constraints=constraint)\n",
    "\n",
    "#Fit the optimizer to the training data\n",
    "optimizer.fit(X_train, y_train, sensitive_features=sensitive_features)\n",
    "\n",
    "# Evaluate the fairness of the model on the test data\n",
    "y_pred = optimizer.predict(X_test)\n",
    "print(len(y_pred))\n",
    "print(y_test.shape)\n",
    "dp_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sensitive_features_test)\n",
    "print(\"Demographic parity difference: \", dp_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49062864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6426116838487973\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        598                        351\n",
      "is_not_recividated                    377                        711\n",
      "Demographic parity difference:  0.024560113308274734\n",
      "Equalized odds difference:  0.06584766584766588\n",
      "False positives for the Caucasian group:  136\n",
      "False positives for the African-American group:  169\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import equalized_odds_difference\n",
    "\n",
    "# Define the sensitive features\n",
    "sensitive_features = np.array([X_train['race_Caucasian'], X_train['race_African-American']]).T\n",
    "sensitive_features_test = np.array([X_test['race_Caucasian'], X_test['race_African-American']]).T\n",
    "\n",
    "# Define the fairness constraint\n",
    "constraint = EqualizedOdds()\n",
    "\n",
    "# Define the model and the optimizer\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs', penalty='l2', random_state=18, n_jobs=-1, class_weight='balanced')\n",
    "optimizer = ExponentiatedGradient(model, constraints=constraint)\n",
    "\n",
    "# Fit the optimizer to the training data\n",
    "optimizer.fit(X_train, y_train, sensitive_features=sensitive_features)\n",
    "\n",
    "# Evaluate the fairness of the model on the test data\n",
    "y_pred = optimizer.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "cm=np.array(confusion_matrix(y_test,y_pred,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)\n",
    "dp_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sensitive_features_test)\n",
    "eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=sensitive_features_test)\n",
    "print(\"Demographic parity difference: \", dp_diff)\n",
    "print(\"Equalized odds difference: \", eo_diff)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "088e1919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate for the Caucasian group:  0.343980343980344\n",
      "False positive rate for the African-American group:  0.3592814371257485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "tn_caucasian, fp_caucasian, fn_caucasian, tp_caucasian = cm_caucasian.ravel()\n",
    "false_positive_rate_caucasian = fp_caucasian / (fp_caucasian + tn_caucasian)\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "tn_african_american, fp_african_american, fn_african_american, tp_african_american = cm_african_american.ravel()\n",
    "false_positive_rate_african_american = fp_african_american / (fp_african_american + tn_african_american)\n",
    "\n",
    "print(\"False positive rate for the Caucasian group: \", false_positive_rate_caucasian)\n",
    "print(\"False positive rate for the African-American group: \", false_positive_rate_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1abdf89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives for the Caucasian group:  186\n",
      "True positives for the African-American group:  345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "true_positives_caucasian = cm_caucasian[1, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "true_positives_african_american = cm_african_american[1, 1]\n",
    "\n",
    "print(\"True positives for the Caucasian group: \", true_positives_caucasian)\n",
    "print(\"True positives for the African-American group: \", true_positives_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85256168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate for the Caucasian group:  0.33415233415233414\n",
      "False positive rate for the African-American group:  0.3373253493013972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix and FPR for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "tn_caucasian, fp_caucasian, fn_caucasian, tp_caucasian = cm_caucasian.ravel()\n",
    "fpr_caucasian = fp_caucasian / (fp_caucasian + tn_caucasian)\n",
    "\n",
    "# Compute the confusion matrix and FPR for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "tn_african_american, fp_african_american, fn_african_american, tp_african_american = cm_african_american.ravel()\n",
    "fpr_african_american = fp_african_american / (fp_african_american + tn_african_american)\n",
    "\n",
    "print(\"False positive rate for the Caucasian group: \", fpr_caucasian)\n",
    "print(\"False positive rate for the African-American group: \", fpr_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d328394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives for the Caucasian group:  136\n",
      "False positives for the African-American group:  169\n",
      "Total False positives are:  305\n",
      "True positives for the Caucasian group:  186\n",
      "True positives for the African-American group:  345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)\n",
    "total_false_positives = false_positives_caucasian + false_positives_african_american\n",
    "print(\"Total False positives are: \", total_false_positives)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred[sensitive_features_test[:, 0] == 1])\n",
    "true_positives_caucasian = cm_caucasian[1, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred[sensitive_features_test[:, 1] == 1])\n",
    "true_positives_african_american = cm_african_american[1, 1]\n",
    "\n",
    "print(\"True positives for the Caucasian group: \", true_positives_caucasian)\n",
    "print(\"True positives for the African-American group: \", true_positives_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2c062ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "104\n",
      "215\n",
      "Equal opportunity difference:  0.02822505090377625\n",
      "True positive rate of caucasian :  0.6401384083044983\n",
      "True positive rate of african american :  0.6119133574007221\n"
     ]
    }
   ],
   "source": [
    "# Calculate true positive rate for the Caucasian group\n",
    "tpr_caucasian = tp_caucasian / (tp_caucasian + fn_caucasian)\n",
    "print(tp_caucasian)\n",
    "print(fn_caucasian)\n",
    "\n",
    "# Calculate true positive rate for the African-American group\n",
    "tpr_african_american = tp_african_american / (tp_african_american + fn_african_american)\n",
    "print(fn_african_american)\n",
    "\n",
    "# Calculate the difference in true positive rates\n",
    "eo_diff = abs(tpr_caucasian - tpr_african_american)\n",
    "\n",
    "print(\"Equal opportunity difference: \", eo_diff)\n",
    "print(\"True positive rate of caucasian : \",tpr_caucasian) \n",
    "print(\"True positive rate of african american : \",tpr_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3aece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
